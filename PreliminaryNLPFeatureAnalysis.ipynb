{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import datetime\n",
    "from scipy import stats \n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import sklearn as sk\n",
    "import nltk\n",
    "import sqlite3\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inventory Cycle Data Analyst</td>\n",
       "      <td>Libratel Inc</td>\n",
       "      <td>- North York, ON</td>\n",
       "      <td>SummaryLibratel is a leading manufacturer and ...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Social Media Data Analyst</td>\n",
       "      <td>URBA Media</td>\n",
       "      <td>- Toronto, ON</td>\n",
       "      <td>PerksWork remote.Flexible hours.Be part of Cal...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intermediate Data Analyst</td>\n",
       "      <td>Instaclick Inc.</td>\n",
       "      <td>- Toronto, ON</td>\n",
       "      <td>This role is responsible for working within th...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finance - Sales and Trading Analyst</td>\n",
       "      <td>KBFX</td>\n",
       "      <td>- North York, ON</td>\n",
       "      <td>CompanyKnightsbridge Foreign Exchange is a cur...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>TD Bank</td>\n",
       "      <td>- Toronto, ON</td>\n",
       "      <td>Tell us your story. Don't go unnoticed. Explai...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Title          Company           Location  \\\n",
       "0         Inventory Cycle Data Analyst     Libratel Inc   - North York, ON   \n",
       "1            Social Media Data Analyst       URBA Media      - Toronto, ON   \n",
       "2            Intermediate Data Analyst  Instaclick Inc.      - Toronto, ON   \n",
       "3  Finance - Sales and Trading Analyst             KBFX   - North York, ON   \n",
       "4                     Data Scientist I          TD Bank      - Toronto, ON   \n",
       "\n",
       "                                         Description    Job Search  \n",
       "0  SummaryLibratel is a leading manufacturer and ...  Data Analyst  \n",
       "1  PerksWork remote.Flexible hours.Be part of Cal...  Data Analyst  \n",
       "2  This role is responsible for working within th...  Data Analyst  \n",
       "3  CompanyKnightsbridge Foreign Exchange is a cur...  Data Analyst  \n",
       "4  Tell us your story. Don't go unnoticed. Explai...  Data Analyst  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('JobsDBa.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT * FROM [Jobs Indeed]')\n",
    "data = cur.fetchall()\n",
    "dfa = pd.DataFrame(data=data, columns=['Job Title', 'Company','Location','Description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3799 entries, 0 to 3798\n",
      "Data columns (total 5 columns):\n",
      "Job Title      3799 non-null object\n",
      "Company        3799 non-null object\n",
      "Location       3799 non-null object\n",
      "Description    3799 non-null object\n",
      "Job Search     3799 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 148.5+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2878 entries, 0 to 2877\n",
      "Data columns (total 5 columns):\n",
      "Job Title      2878 non-null object\n",
      "Company        2878 non-null object\n",
      "Location       2878 non-null object\n",
      "Description    2878 non-null object\n",
      "Job Search     2878 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 112.5+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 990 entries, 0 to 989\n",
      "Data columns (total 5 columns):\n",
      "Job Title      990 non-null object\n",
      "Company        990 non-null object\n",
      "Location       990 non-null object\n",
      "Description    990 non-null object\n",
      "Job Search     990 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 38.8+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1378 entries, 0 to 1377\n",
      "Data columns (total 5 columns):\n",
      "Job Title      1378 non-null object\n",
      "Company        1378 non-null object\n",
      "Location       1378 non-null object\n",
      "Description    1378 non-null object\n",
      "Job Search     1378 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 53.9+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2867 entries, 0 to 2866\n",
      "Data columns (total 5 columns):\n",
      "Job Title      2867 non-null object\n",
      "Company        2867 non-null object\n",
      "Location       2867 non-null object\n",
      "Description    2867 non-null object\n",
      "Job Search     2867 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 112.1+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11912 entries, 0 to 1377\n",
      "Data columns (total 5 columns):\n",
      "Job Title      11912 non-null object\n",
      "Company        11912 non-null object\n",
      "Location       11912 non-null object\n",
      "Description    11912 non-null object\n",
      "Job Search     11912 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 558.4+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7245"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57450\n",
      "<bound method _cs_matrix.toarray of <11912x57450 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2734829 stored elements in Compressed Sparse Row format>>\n"
     ]
    }
   ],
   "source": [
    "punc = ['.',',','\"','?', '!', ':',';','(',')','[',']','{','}','%','$','#','@','&','*',\"'\"]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(punc)\n",
    "desc = dfc['Description'].values\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_words)\n",
    "X = vectorizer.fit_transform(desc)\n",
    "word_features = vectorizer.get_feature_names()\n",
    "print(len(word_features))\n",
    "print(X.toarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57450\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "# tokenizer = RegexpTokenizer(r'[a-zA-Z\\']+')\n",
    "\n",
    "# def tokenize(text):\n",
    "#     return [stemmer.stem(word) for word in tokenizer.tokenize(text.lower())]\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(stop_words = stop_words)\n",
    "X2 = vectorizer2.fit_transform(desc)\n",
    "word_features2 = vectorizer2.get_feature_names()\n",
    "print(len(word_features2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:2130: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  dtype=dtype)\n",
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:2130: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  dtype=dtype)\n",
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:2130: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  dtype=dtype)\n",
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:2130: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  dtype=dtype)\n",
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:2130: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words = stop_words)\n",
    "dlist = [dfa, dfmle, dfde, dfbd, dfs]\n",
    "dout = []\n",
    "for df in dlist:\n",
    "    X = count_vect.fit_transform(df['Description'])\n",
    "    featname = count_vect.get_feature_names()\n",
    "    dfcount = pd.DataFrame(data=X.toarray(), columns=featname)\n",
    "    dout.append(dfcount)\n",
    "dtitle = ['Data Analyst Count Vector Top 50','Machine Learning Engineer Count Vector Top 50','Data Engineer Count Vector Top 50','Big Data Count Vector Top 50','Data Scientist Count Vector Top 50']\n",
    "for df,title in zip(dout, dtitle):\n",
    "    wordcomp = df.mean().tolist()\n",
    "    label = list(df.columns.values)\n",
    "    win = []\n",
    "    for m,w in zip(wordcomp,label):\n",
    "        ls = [w,m]\n",
    "        win.append(ls)\n",
    "    dfwc = pd.DataFrame(data=win, columns=['Word','Mean Appearance'])\n",
    "    dfwcb = dfwc.nlargest(50,'Mean Appearance')\n",
    "    dfwcb.to_sql(name=title, con =conn, if_exists='replace')\n",
    "#     cur.execute('CREATE TABLE IF NOT EXISTS [' + title + ']([Word] TEXT, [Mean Appearance] INTEGER, UNIQUE([Word]))')\n",
    "#     cur.execute('INSERT OR IGNORE INTO [' + title + ']([Word],[Mean Appearance]) VALUES(?,?)', (dfwcb['Word'],dfwcb['Mean Appearance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``', 'ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Word  Mean Appearance\n",
      "11789           data         6.161358\n",
      "7622        business         4.006054\n",
      "16254     experience         3.828902\n",
      "40130           team         2.815215\n",
      "43945           work         2.795999\n",
      "37211          skill         2.288497\n",
      "44730              ’         2.130297\n",
      "4485        analysis         2.116873\n",
      "3152         ability         1.935246\n",
      "24319     management         1.779942\n",
      "32035        project         1.600421\n",
      "31502        process         1.596473\n",
      "39438        support         1.555146\n",
      "44464           year         1.476441\n",
      "4646         analyst         1.432745\n",
      "35626              s         1.409581\n",
      "11503       customer         1.396947\n",
      "200               --         1.271124\n",
      "31692        product         1.270071\n",
      "28326    opportunity         1.238747\n",
      "4803       analytics         1.188471\n",
      "34308       required         1.170571\n",
      "38991         strong         1.151356\n",
      "33982         report         1.139247\n",
      "20765      including         1.112135\n",
      "34003      reporting         1.111345\n",
      "22671      knowledge         1.089234\n",
      "36612        service         1.085812\n",
      "9764         company         1.084759\n",
      "34481    requirement         1.080548\n",
      "21056    information         1.068176\n",
      "44027        working         1.050540\n",
      "9110          client         0.978679\n",
      "17224      financial         0.976046\n",
      "13135    development         0.974467\n",
      "27082            new         0.964991\n",
      "12534         degree         0.944722\n",
      "37740       solution         0.941827\n",
      "22321            job         0.939984\n",
      "41161           tool         0.915504\n",
      "15297    environment         0.890234\n",
      "9685   communication         0.867860\n",
      "32337        provide         0.857068\n",
      "35384           role         0.838642\n",
      "33770        related         0.837589\n",
      "30543       position         0.834957\n",
      "4778      analytical         0.832324\n",
      "24749      marketing         0.823901\n",
      "21316        insight         0.802580\n",
      "40432     technology         0.802580\n"
     ]
    }
   ],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(txt):\n",
    "    return [lemma.lemmatize(word) for word in word_tokenize(txt.lower())]\n",
    "count_vect = CountVectorizer(stop_words = stop_words, tokenizer=tokenize)\n",
    "dlist = [dfa, dfmle, dfde, dfbd, dfs]\n",
    "dout = []\n",
    "\n",
    "for df in dlist:\n",
    "    X = count_vect.fit_transform(df['Description'])\n",
    "    featname = count_vect.get_feature_names()\n",
    "    dfcount = pd.DataFrame(data=X.toarray(), columns=featname)\n",
    "    dout.append(dfcount)\n",
    "\n",
    "wordcomp = dout[0].mean().tolist()\n",
    "label = list(dout[0].columns.values)\n",
    "win = []\n",
    "for m,w in zip(wordcomp,label):\n",
    "    ls = [w,m]\n",
    "    win.append(ls)\n",
    "dfwc = pd.DataFrame(data=win, columns=['Word','Mean Appearance'])\n",
    "dfwc.head(5)\n",
    "dfwc.sort_values(by=['Mean Appearance'], ascending=False)\n",
    "dfwcb = dfwc.nlargest(150,'Mean Appearance')\n",
    "print(dfwcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00001</th>\n",
       "      <th>00003901</th>\n",
       "      <th>00004500</th>\n",
       "      <th>00004959</th>\n",
       "      <th>000application</th>\n",
       "      <th>000s</th>\n",
       "      <th>000year</th>\n",
       "      <th>000欢迎应届毕业留学生申请</th>\n",
       "      <th>...</th>\n",
       "      <th>经济</th>\n",
       "      <th>职位类型</th>\n",
       "      <th>英文</th>\n",
       "      <th>计算机等stem类皆可</th>\n",
       "      <th>请加wx</th>\n",
       "      <th>需要有基础编程技能</th>\n",
       "      <th>需要至少学士学历或在读生</th>\n",
       "      <th>ﬁeld</th>\n",
       "      <th>ﬁnancial</th>\n",
       "      <th>ﬁrm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022558</td>\n",
       "      <td>0.018063</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.266569</td>\n",
       "      <td>0.226859</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>0.066921</td>\n",
       "      <td>0.138367</td>\n",
       "      <td>0.081644</td>\n",
       "      <td>0.173456</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.142548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142548</td>\n",
       "      <td>0.230253</td>\n",
       "      <td>0.230253</td>\n",
       "      <td>0.142548</td>\n",
       "      <td>0.142548</td>\n",
       "      <td>0.142548</td>\n",
       "      <td>0.142548</td>\n",
       "      <td>0.083831</td>\n",
       "      <td>0.083831</td>\n",
       "      <td>0.094223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                00          000        00001     00003901     00004500  \\\n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
       "mean      0.004624     0.005664     0.000012     0.000012     0.000018   \n",
       "std       0.022558     0.018063     0.000748     0.000748     0.001086   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.266569     0.226859     0.046122     0.046122     0.066921   \n",
       "\n",
       "          00004959  000application         000s      000year  000欢迎应届毕业留学生申请  \\\n",
       "count  3799.000000     3799.000000  3799.000000  3799.000000     3799.000000   \n",
       "mean      0.000036        0.000021     0.000046     0.000093        0.000038   \n",
       "std       0.002245        0.001325     0.002814     0.003319        0.002313   \n",
       "min       0.000000        0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.000000        0.000000     0.000000     0.000000        0.000000   \n",
       "50%       0.000000        0.000000     0.000000     0.000000        0.000000   \n",
       "75%       0.000000        0.000000     0.000000     0.000000        0.000000   \n",
       "max       0.138367        0.081644     0.173456     0.137504        0.142548   \n",
       "\n",
       "          ...                经济         职位类型           英文  计算机等stem类皆可  \\\n",
       "count     ...       3799.000000  3799.000000  3799.000000  3799.000000   \n",
       "mean      ...          0.000038     0.000061     0.000061     0.000038   \n",
       "std       ...          0.002313     0.003736     0.003736     0.002313   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          0.142548     0.230253     0.230253     0.142548   \n",
       "\n",
       "              请加wx    需要有基础编程技能  需要至少学士学历或在读生         ﬁeld     ﬁnancial  \\\n",
       "count  3799.000000  3799.000000   3799.000000  3799.000000  3799.000000   \n",
       "mean      0.000038     0.000038      0.000038     0.000022     0.000022   \n",
       "std       0.002313     0.002313      0.002313     0.001360     0.001360   \n",
       "min       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
       "max       0.142548     0.142548      0.142548     0.083831     0.083831   \n",
       "\n",
       "               ﬁrm  \n",
       "count  3799.000000  \n",
       "mean      0.000025  \n",
       "std       0.001529  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       0.094223  \n",
       "\n",
       "[8 rows x 32002 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words = stop_words)\n",
    "dlist = [dfa, dfmle, dfde, dfbd, dfs]\n",
    "dout = []\n",
    "for df in dlist:\n",
    "    X = tfidf_vect.fit_transform(df['Description'])\n",
    "    featname = tfidf_vect.get_feature_names()\n",
    "    dfcount = pd.DataFrame(data=X.toarray(), columns=featname)\n",
    "    dout.append(dfcount)\n",
    "dtitle = ['Data Analyst Tfidf Top 150','Machine Learning Engineer Tfidf Top 150','Data Engineer Tfidf Top 150','Big Data Tfidf Top 150','Data Scientist Tfidf Top 150']\n",
    "dout[0].describe()\n",
    "for df,title in zip(dout, dtitle):\n",
    "    wordcomp = df.mean().tolist()\n",
    "    label = list(df.columns.values)\n",
    "    win = []\n",
    "    for m,w in zip(wordcomp,label):\n",
    "        ls = [w,m]\n",
    "        win.append(ls)\n",
    "    dfwc = pd.DataFrame(data=win, columns=['Word','TF-IDF'])\n",
    "    dfwcb = dfwc.nlargest(150,'TF-IDF')\n",
    "    dfwcb.to_sql(name=title, con =conn, if_exists='replace')\n",
    "#     cur.execute('CREATE TABLE IF NOT EXISTS [' + title + ']([Word] TEXT, [Mean Appearance] INTEGER, UNIQUE([Word]))')\n",
    "#     cur.execute('INSERT OR IGNORE INTO [' + title + ']([Word],[Mean Appearance]) VALUES(?,?)', (dfwcb['Word'],dfwcb['TF-IDF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words = stop_words)\n",
    "X = tfidf_vect.fit_transform(dfc['Description'])\n",
    "featname = tfidf_vect.get_feature_names()\n",
    "dfcount = pd.DataFrame(data=X.toarray(), columns=featname)\n",
    "dtitle = ['Data Analyst Tfidf Top 150','Machine Learning Engineer Tfidf Top 150','Data Engineer Tfidf Top 150','Big Data Tfidf Top 150','Data Scientist Tfidf Top 150']\n",
    "title= 'Comparison TFIDF Top 150'\n",
    "wordcomp = dfcount.mean().tolist()\n",
    "label = list(dfcount.columns.values)\n",
    "win = []\n",
    "for m,w in zip(wordcomp,label):\n",
    "    ls = [w,m]\n",
    "    win.append(ls)\n",
    "dfwc = pd.DataFrame(data=win, columns=['Word','TF-IDF'])\n",
    "dfwcb = dfwc.nlargest(50,'TF-IDF')\n",
    "dfwcb.to_sql(name=title, con =conn, if_exists='replace')\n",
    "dfc.to_sql(name='Combined Table', con=conn, if_exists='replace')\n",
    "# cur.execute('CREATE TABLE IF NOT EXISTS [' + title + ']([Word] TEXT, [Mean Appearance] INTEGER, UNIQUE([Word]))')\n",
    "# cur.execute('INSERT OR IGNORE INTO [' + title + ']([Word],[Mean Appearance]) VALUES(?,?)', (dfwcb['Word'],dfwcb['TF-IDF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
